{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors, Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download google pretrained word vectors: https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit\n",
    "## 1.5G, 3 million words trained on 100 billion words from google news dataset\n",
    "## Relevant params: https://radimrehurek.com/gensim/models/keyedvectors.html\n",
    "\n",
    "model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.36914062,  0.171875  ,  0.30273438, -0.08056641, -0.20507812,\n",
       "        0.3984375 ], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get word vector of a word\n",
    "sample_word = model['icecream']\n",
    "sample_word[4:10]  # here I'm just showing a subarray, otherwise the array is huge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'princess', 0.6431564688682556), (u'queens', 0.6387216448783875), (u'very_pampered_McElhatton', 0.5774043202400208), (u'Queen_Consort', 0.5504266619682312), (u'Queen', 0.5450494289398193), (u'princesses', 0.5421540141105652), (u'duchess', 0.5339502692222595), (u'empress', 0.5262109637260437), (u'monarch', 0.5216404795646667), (u'Princess', 0.5202960968017578)]\n"
     ]
    }
   ],
   "source": [
    "# find most similar words\n",
    "\n",
    "print(model.most_similar(positive=['woman', 'queen'], negative=['man']))  # this took very long time to run..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emmanuel\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.26757812,  0.02929688, -0.18359375, -0.15722656, -0.09179688,\n",
       "        0.0168457 ], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pick out the odd token out...\n",
    "\n",
    "print(model.doesnt_match(\"Emmanuel's cats are very adorable! In fact Emmanuel is an adorable cat! As lovely as Totoro!\".split()))\n",
    "\n",
    "## but the word vector does have Emmanuel this word\n",
    "sample_word = model['Emmanuel']\n",
    "sample_word[4:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0830172488544\n",
      "0.0624687042684\n",
      "0.0583377236346\n",
      "0.105000703299\n",
      "0.289815366273\n"
     ]
    }
   ],
   "source": [
    "print(model.similarity('Totoro', 'Emmanuel'))\n",
    "print(model.similarity('Cat', 'Emmanuel'))\n",
    "print(model.similarity('Icecream', 'Emmanuel'))\n",
    "print(model.similarity('ice', 'fire'))\n",
    "print(model.similarity('Hanhan', 'Emmanuel'))  # ha, much higher!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My own model, train on only 3 sentences\n",
    "## min_count - lowest frequency to be included in the vocabulary\n",
    "## size - size/dimensions of the word vector\n",
    "## workers - number of cores used in parallelization\n",
    "\n",
    "s1 = \"Emmanuel's cats are very adorable\"\n",
    "s2 = \"In fact Emmanuel is an adorable cat\"\n",
    "s3 = \"Emmanuel is as lovely as Totoro\"\n",
    "sentences = [s1.split(), s2.split(), s3.split()]\n",
    "my_model = Word2Vec(sentences, min_count=1,size=300,workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[\"Emmanuel's\", 'cats', 'are', 'very', 'adorable'],\n",
       " ['In', 'fact', 'Emmanuel', 'is', 'an', 'adorable', 'cat'],\n",
       " ['Emmanuel', 'is', 'as', 'lovely', 'as', 'Totoro']]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0140343215701\n"
     ]
    }
   ],
   "source": [
    "# When check similarity, words have to be in the vocabulary of your own model\n",
    "\n",
    "print(my_model.wv.similarity('Emmanuel', 'adorable'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
